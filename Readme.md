# Tugas Praktikum

Nama : Yudas Malabi

Kelas : TI 3C / 20

NIM : 2041720054

1. Kode 1
    * mylist : 
    * myschema : 
2. Kode 2
    * spark
    * createDataFrame : 
3. Kode 3
    * parallelize
    * toDF
4. Kode 4
    * hadoop
    * fs
    * put
5. Kode 5
    * pyspark.sql
    * SQLContext
    * createOrReplaceTempView
    * show
6. Kode 6
    * textFile
    * map
    * lambda
    * strip
    * StructField
    * StringType
7. Kode 7
    * spark.read.format
    * jdbc
    * options
    * load
8. Kode 8
    * show
9. Kode 9
    * collect
    * rdd
    * take
10. Kode 10
    * makeRDD
    * Seq
    * createDataset
11. Kode 11
    * filter
12. Kode 12
    * as
    * toDF
    * first
13. Kode 13
    * listDatabases : Mengembalikan daftar database yang tersedia di semua sesi.
    * listTables : Mengembalikan daftar tabel/tampilan dalam database yang ditentukan.
    * listFunctions : Mengembalikan daftar fungsi yang terdaftar di database yang ditentukan.
    * isCached : Mengembalikan nilai true jika tabel saat ini di-cache dalam memori.
    * select : Memproyeksikan sekumpulan ekspresi dan mengembalikan DataFrame baru.
14. Kode 14
    * Read : menyesuaikan cara data dibaca dari source data
    * text : membaca file teks ke dalam DataFrame
15. Kode 15
    * load : Memuat data dari source data dan mengembalikannya sebagai DataFrame.
    * json : membaca file JSON ke dalam Spark DataFrame
    * format : load sebuah file / memformat hasil file dengan tipe data tertentu
    * printSchema : Mencetak skema dataframe dalam format tree.
16. Kode 16
    * write : untuk menyimpan konten DataFrame non-streaming ke penyimpanan eksternal.
    * save : untuk menyimpan konten DataFrame ke sumber data.
17. Kode 17
    * parquet : Menyimpan konten DataFrame dalam format Parket pada path yang ditentukan.
18. Kode 18
    * Options : menyesuaikan / memberikan opsi bagaimana data dibaca dari sumbernya.
    * inferSchema : alternatif dari fungsi schema sebagai penyesuaian tipe data dari kolom pada file csv dengan lebih cepat.
    * csv : Memuat file CSV dan mengembalikan hasilnya sebagai DataFrame.
    * header : opsi jika file csv memiliki header, maka baris pertama akan digunakan sebagai nama kolom.
    * codec: Opsi ini digunakan untuk menentukan codec kompresi yang akan digunakan saat pada output. contoh codec yang disupport adalah gzip, snappy, dan bzip2.